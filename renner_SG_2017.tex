\documentclass[11pt,a4paper]{article}
%\pagestyle{headings}
%\linespread{1.6}

% Set up 20 mm margins on each side
\hoffset -5.4mm
\voffset -5.4mm

\oddsidemargin 0.0in
\evensidemargin 0.0in

\textwidth 17.0cm
\textheight 232mm

\topmargin 0.0in
\headheight 4mm
\headsep 9mm
\footskip 12mm

%\usepackage{hyperref,color,graphicx,braket,mathrsfs,simplewick,slashed,amsmath,amssymb,feynmf,ifpdf,pdflscape,wrapfig,fancyhdr,lastpage,etoolbox}
\usepackage{hyperref,xcolor,graphicx,ifpdf,wrapfig,fancyhdr,lastpage,etoolbox,tocloft,multirow,array,pdflscape,enumitem,eurosym,amssymb,titlesec}
\usepackage[square,numbers]{natbib}
%\usepackage[backend=bibtex,style=authoryear]{biblatex}
%\addbibresource{/home/josh/Dropbox/bibliography/xenon_fulbright.bib}

\hypersetup{colorlinks,%
            citecolor=black,%
            linkcolor=black,%
            filecolor=black,%
            urlcolor=black}

\bibliographystyle{JHEP}
%\bibliographystyle{apsrev4-1}

% Set up the header and footer.
\makeatletter
\patchcmd{\@fancyhead}{\rlap}{\color{black}\rlap}{}{}
\patchcmd{\@fancyfoot}{\rlap}{\color{black}\rlap}{}{}
\makeatother

% Set up the title spacing
\titlespacing\section{0pt}{4pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}
\titlespacing\subsection{0pt}{4pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}
\titlespacing\subsubsection{0pt}{4pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}

\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\lhead{Renner}
\chead{Part B1}
\rhead{DNNEXT}
\cfoot{\thepage}

% To keep the numbering of the table of contents consistent.
\tocloftpagestyle{fancy}

% Table column formatting: from 
% http://tex.stackexchange.com/questions/12703/how-to-create-fixed-width-table-columns-with-text-raggedright-centered-raggedlef
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\begin{document}
\input{Commands.tex}

\begin{center}
\large
\textbf{ERC Starting Grant 2017}\\
Research proposal [Part B1]\\[2.0\baselineskip]
\Large
\textbf{Deep Learning in Detector Physics Analyses}\\[1.0\baselineskip]
\LARGE
\textbf{DNNEXT}\\[1.0\baselineskip]
\end{center}
% \vspace{5.5 in}

\noindent PI: Joshua Edward Renner\\
\noindent Host Institution: Universidad de Valencia\\
\noindent Proposal Duration: 60 months\\

The development of deep learning has been realized over the past 10 years with the rise of computing power, which has now permitted the training of neural networks with many layers
of neurons in series.  Such networks have proven capable of high-level abstraction, that is, neurons in deeper layers have been shown to indicate the presence of complex features in a dataset, 
such as the presence of macroscopic objects in images.  It is of great interest to study how such techniques can be applied to physics, and in particular particle detection and tracking, a field 
in which problems exist similar to those to which deep learning has been initially applied.  We propose an in-depth study of the use of deep neural networks in the reconstruction and classification of events in NEXT (Neutrino Experiment with a Xenon TPC), an experiment searching for neutrinoless double beta decay in $^{136}$Xe. We discuss the results that have already been obtained which indicate the advantages of deep neural networks over classical analysis methods and highlight their merit for further study.
\newpage
\normalsize

\newpage
%\setcounter{page}{1}
{\textbf{Section A: Extended Synopsis of the scientific proposal}}

\newpage
\noindent{\textbf{Section B: Curriculum Vitae}}\\[1.0\baselineskip]
\input{src/renner_CV.tex}

\newpage
{\textbf{\emph{Appendix: All on-going and submitted grants and funding of the PI (Funding ID)}}}\\

\noindent\textbf{On-going grants}\\

\noindent\textbf{Grant applications}\\

\newpage
{\textbf{Section C: Early achievements track-record}}

\newpage
\chead{Part B2}
\begin{center}
	\large
	\textbf{ERC Starting Grant 2017}\\
	Research proposal [Part B1]\\[2.0\baselineskip]
\end{center}

\noindent\textbf{Part B2: \underline{The scientific proposal}}\\

{\noindent\textbf{Section A: State-of-the-art and objectives}}\\
In recent years, increasingly sensitive null results (cite) in searches for neutrinoless double beta ($0\nu\beta\beta$) decay have made it clear that an ultra-low background experiment 
employing on the order of tonnes of active mass will be necessary to have a meaningful chance of discovery.  Such an experiment would require excellent energy resolution as well as the use
additional mechanisms for background rejection.  Gaseous xenon enriched in the isotope $^{136}$Xe has shown strong potential for being the 
detection medium of choice for a discovery experiment due to its relatively low cost, ability to act as both source and detector, outstanding energy resolution, and the long ionization 
tracks produced by electrons at energies of order $Q_{\beta\beta}$, which can be analyzed to provide increased background rejection.  NEXT is working towards a presently competitive search 
for $0\nu\beta\beta$ decay with 100 kg of xenon enriched to 90\% in $^{136}$Xe, which will also demonstrate the capacity to benefit from these advantages of gaseous xenon with a 
large detector and thus their potential applicability at the tonne-scale.

Because the senstivity of a background-free $0\nu\beta\beta$ search grows as the square root of the product of the (active mass) $\times$ (exposure time), while in the presence of background the sensitivity increases only as the \emph{fourth} root of the same product, background rejection is of utmost importance. As experiments grow to larger masses, the ability to interpret the information available to reject the maximum amount of background possible becomes vital to the success of the experiment.  It has been recently shown (cite DNN paper) that the conventional analysis of NEXT that has been developed up to this point can be potentially improved using deep neural networks (DNNs) to analyze receonstructed tracks in the experiment. \emph{Such improvements in the analysis will be critical in reaching the ultimate sensitivity of NEXT and in reaching the targeted sensitivity in a larger, tonne-scale experiment.}\\

\noindent\textbf{\textbullet\,\,Objectives}\\
The main objectives of this proposal include:

\begin{enumerate}[itemsep=-1mm]
	\item[1.] To understand the workings and limitations of DNNs as applied to classification and reconstruction in NEXT.
	\item[2.] To produce a DNN-based analysis for NEXT, to be developed and tested alongside acquisition of NEW data.
	\item[3.] To apply the DNN-based analysis to data acquired from the NEXT-100 detector.
	\item[4.] To explore further applications of DNNs in NEXT and particle physics.
\end{enumerate}

\noindent\textbf{Neutrinoless Double-Beta Decay and NEXT}\\
The prospect of demonstrating the Majorana nature of the neutrino and violation of lepton number conservation has inspired a variety of experiments to search for $0\nu\beta\beta$ decay in several candidate isotopes.  The experiments GERDA and EXO, using isotopes $^{76}$Ge and $^{136}$Xe respectively, have set lower limits on the half-life of $0\nu\beta\beta$ decay, $T_{1/2}^{0\nu}$, of greater than $10^{25}$ years.  These and other experiments, such as CUORE, MAJORANA, NEXT, SNO+, and Super-NEMO intend to constrain $T_{1/2}^{0\nu}$ with a lower bound of order $10^{26}$ years.  Recently, KamLAND-ZEN obtained a lower limit of $T_{1/2}^{0\nu} > 1.07\times 10^{26}$ years \cite{KamLANDZen_2016}. The predicted background rate in NEXT-100 is $4 \times 10^{-4}$ counts/(keV kg yr), giving rise to a lower limit on  of $T_{1/2} > 6.0\times 10^{25}$ years (90\% CL) for 3 effective years of running time \cite{NEXT_sensitivity}.  Improvements in background rejection are essential to the operation of NEXT and for realizing sensitivities of order $10^{27}$ years in future tonne-scale experiments.

The core idea behind the NEXT experiment is the electroluminescent (EL) time projection chamber (TPC). In this type of detector, energy is deposited in some active volume filled with a detector medium (high pressure xenon gas, in the case of NEXT), by ionizing radiation such as energetic electrons produced by radioactive decay within the volume or gamma rays which convert via Compton scattering, pair production, or photoabsorption. The ionizing energetic particle produces a track of ionization and excitation in the active medium. The excitation gives rise to scintillation which is detected immediately by photosensors such as photomultiplier tubes (PMTs). This scintillation, called S1, is used to mark the start of the event, after which some delay occurs while the ionized electrons are drifted in an applied electric field to a readout plane at one end of the detector. 

At the readout plane, the ionized electrons are drifted in a much higher electric field through an amplification region in which they are accelerated enough to excite but not ionize the xenon medium.  Each electron produces a number of xenon excitations determined by the magnitude of the electric field in the amplification region, its width, and the operating gas pressure.  These excitations give rise to additional photons (called S2), so that some number of photons is generated for each electron.  The S2 photons generated in this process, called electroluminescence, can then be detected by photosensors to give energy and position information of the event. In NEXT, a cylindrical TPC design is employed, in which a \emph{tracking plane} of silicon photomultipliers (SiPMs) is placed just behind a narrow amplification region, and an \emph{energy plane} of PMTs is installed on one end of the vessel (see figure \ref{fig.SS}, left). In addition to a precise energy measurement to reject background events with energy outside of a narrow region near $Q_{\beta\beta}$, a primary advantage of the NEXT concept is the ability to accurately reconstruct tracks and utilize the topological signature of events to distinguish between signal ($0\nu\beta\beta$) and background events, the majority of which would be produced by gamma rays generating single-electrons.  As also shown in figure \ref{fig.SS}, because of the Bragg peak in energy loss of an energetic electron which gives rise to a dense region (``blob'') of ionization at the end of its ionization track, a two-electron signal event will leave an ionization track with two such ``blobs,'' while a single-electron background event will exhibit only one.

\begin{figure}[!htb]
	\centering
	\includegraphics[width= 0.42\textwidth]{fig/nextEL.pdf}
	\includegraphics[width= 0.56\textwidth]{fig/TrackSignature.pdf}
	\caption{The NEXT concept. (Left, figure from \cite{Alvarez:2013gxa}) In an asymmetrical EL TPC, energetic electrons produce primary scintillation (S1) and ionization initially, and the ionization is drifted to the EL readout plane and amplified, producing additional scintillation photons (S2).  The energy (PMT) plane detects S1 (coordinate $z$) and S2 (energy), while the finer-resolution tracking (SiPM) plane measures S2 to deduce $(x,y)$ coordinates, resulting in a full 3D reconstruction of the track and its energy. (Right, figure from \cite{NEXT_sensitivity}) The anticipated topologies of signal and background events in a $0\nu\beta\beta$ search with high pressure xenon gas.} \label{fig.SS}
\end{figure}

In order to fully benefit from the potential of the topological signature, a sound procedure for track reconstruction and classification is essential. It has already been shown through a detailed comparison between Monte Carlo and data from the prototype detector NEXT-DEMO that the topological signature can be used to significantly reject background at an allowable cost in efficiency \cite{NEXT_topology}. A Monte Carlo study in \cite{NEXT_DNN} showed that such a topological analysis could be performed significantly better with deep learning techniques.

The conventional NEXT analysis is performed by reconstructing a 3D track in the form of ``hits'' from the pattern of light cast on the tracking plane of SiPM detectors during EL readout. As the EL light arrives at the PMT plane when the ionization electrons of the tracks arrive at the EL plane, the track can be divided into ``slices'' in time and therefore, as drift time is related to axial location within the TPC, in the z-coordinate. The charge detected in each SiPM over each time slice is summed, and from these charges one or more hits are reconstructed by locating the SiPM with the maximum charge, using the charges of neighboring SiPMs in either a weighted sum (barycenter) or 2D Gaussian fit to reconstruct a single point, and repeating this process discarding the charges already considered. The reconstructed volume is then divided into 3D rectangular volumes or ``voxels,'' each of which is filled with the energy of each reconstructed hit that lies within it. Sequences of connected voxels are denoted as ``tracks'' and multi-track events are discarded.

\begin{figure}[!htb]
	\centering
	\includegraphics[width= 0.42\textwidth]{fig/sipm_map.png}
	\includegraphics[width= 0.46\textwidth]{fig/xy_proj.png}
	\caption{Conventional NEXT track reconstruction. (Left, figure from \cite{NEXT_topology}) Example of tracking plane signals for a single z-slice in EL readout. (Right, figure from \cite{NEXT_topology}) Example x-y projection of a voxelized track produced by a $^{22}$Na gamma source.} \label{fig.recon}
\end{figure}

The analysis continues by considering the single connected track as a graph and using the Breadth First Search (BFS) algorithm to find the shortest path between each pair of voxels in the event. The longest of such shortest ordered paths is considered to be the final track, and the extremes of this path are identified. The energy in the voxels nearby the two extremes can be summed and compared: in cases of signal two larger values (``blobs'') should be found, and only one in the case of background (see figure).  This algorithm, though reliable in many cases and shown to give good performance, has the major shortcoming that it must operate on a path with a clear beginning and end. Attempts to improve upon this algorithm by applying an external magnetic field and fitting an ordered track to an expected path using a Kalman filter have failed to improve significantly upon the results of the original algorithm despite showing promising results in theory \cite{NEXT_BFIELD}. This is because it was realized that, though in many cases a straightforward ordered reconstruction of an event is obtainable, in a significant number of cases \emph{it is very difficult or impossible to determine the ordering of a reconstructed track.}  This is mainly due to electron multiple scattering, or the sudden changes in course (by large angles) of an ionizing electron due to many scattering interactions with the atoms of the gas.  Such effects produce twisted tracks of varying geometries, often looping back on themselves and crossing. Determining the ordering of an arbitrary event containing multiple crossings is challenging and may require an algorithm that considers many special cases.

Performing such an analysis with a DNN does not require pre-determining an ordered path. In some sense the DNN handles this, and as it contains many parameters, it should be able to cover many more special cases than feasible for an analytic algorithm. Replacing the blob-based analysis with a DNN has already been shown to yield significant improvement \cite{NEXT_DNN}. In fact, the DNN does not even require a connected track to operate; the reconstructed z-projections determined in the previous phase of the analysis can be passed directly to the DNN. It is such an analysis we propose to construct. By presenting a suitable DNN with a statistically broad sample of training events, one should be able to make use of all possible physical information in making the classification decision. We intend to apply such a strategy to obtain the ultimate sensitivity in NEXT and reveal how such an analysis can be applied to similar problems in particle physics.

\noindent\textbf{Deep Learning}\\
Several problems in particle physics have already been addressed using deep learning.
- describe deep learning and discuss what has been done, particularly in physics
- detail on CNNs
- also want to show how DNNs can be used in physics applications (IMPORTANT to note other potential benefits and give examples)

{\noindent\textbf{Section B: Methodology}}\\
Discuss use of Python (Keras, TF) and previous use of Caffe/DIGITS.  Discuss use of GPUs.  Develop plan for analysis and procedure for understanding DNNs.  Show what has already been done.\\

- diagram of proposed analysis construction chain

{\noindent\textbf{Section C: Resources (including project costs)}}\\

\bibliography{dnnext}

\end{document}